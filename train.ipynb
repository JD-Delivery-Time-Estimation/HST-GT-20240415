{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.utils_new import get_train_data,get_graph,get_y_time\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from Model.HST_GT import HGT\n",
    "from Utils.Metric_utils import *\n",
    "from datetime import datetime\n",
    "Recordpath = 'Records/'\n",
    "Logdir = Recordpath + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '/'\n",
    "os.mkdir(Logdir)\n",
    "os.mkdir(Logdir+'Model_Save/')\n",
    "# split train test\n",
    "N_train = int(240 * 0.8)\n",
    "N_test = int(240 * 0.2)\n",
    "\n",
    "train_range = list(range(N_train))\n",
    "test_range = list(range(N_train,N_train+N_test))\n",
    "import numpy as np\n",
    "y_all_t_all,y_wh_t_all,y_pack_t_all,y_sort_t_all = get_y_time()\n",
    "y_all_t_all = torch.from_numpy(np.array(y_all_t_all)).to('cpu').to(torch.float32)\n",
    "y_wh_t_all = torch.from_numpy(np.array(y_wh_t_all)).to('cpu').to(torch.float32)\n",
    "y_pack_t_all = torch.from_numpy(np.array(y_pack_t_all)).to('cpu').to(torch.float32)\n",
    "y_sort_t_all = torch.from_numpy(np.array(y_sort_t_all)).to('cpu').to(torch.float32)\n",
    "\n",
    "train_data_wh,train_data_sort ,train_data_background_wh,train_data_background_sort\\\n",
    ",y_all_t,y_wh_t ,y_sort_t ,y_pack_t \\\n",
    ",wh_mask,sort_mask,wh_pack_mask,sort_pack_mask\\\n",
    ",downstream_mask,context_mask\\\n",
    ",graph = get_train_data()\n",
    "\n",
    "\n",
    "model = HGT(hidden_channels=32,  num_heads=4, num_layers=3,temporal_features=4,back_features=3,data=graph)\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_wh = torch.from_numpy(train_data_wh).to('cuda:0').to(torch.float32)\n",
    "train_data_sort = torch.from_numpy(train_data_sort).to('cuda:0').to(torch.float32)\n",
    "train_data_background_wh = torch.from_numpy(train_data_background_wh).to('cuda:0').to(torch.float32)\n",
    "train_data_background_sort = torch.from_numpy(train_data_background_sort).to('cuda:0').to(torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "wh_mask = wh_mask.to(device).to(torch.float32)\n",
    "sort_mask = sort_mask.to(device).to(torch.float32)\n",
    "mask_in = {\n",
    "    'Node1':wh_mask,\n",
    "    'Node2':sort_mask\n",
    "}\n",
    "wh_pack_mask = wh_pack_mask.to(device).to(torch.float32)\n",
    "sort_pack_mask = sort_pack_mask.to(device).to(torch.float32)\n",
    "mask_pack_in = {\n",
    "    'Node1':wh_pack_mask,\n",
    "    'Node2':sort_pack_mask\n",
    "}\n",
    "downmask_ins =torch.from_numpy(downstream_mask).to(device).to(torch.float32)\n",
    "cmask_ins=torch.from_numpy(context_mask).to(device).to(torch.float32)\n",
    "import numpy as np\n",
    "y_all_ts = [] \n",
    "y_wh_ts = []\n",
    "y_sort_ts = []\n",
    "y_pack_ts = []\n",
    "\n",
    "for i in range(240):\n",
    "    \n",
    "    y_all_ts.append(torch.from_numpy(np.array(y_all_t[i])).to(device).to(torch.float32).view(-1,1))\n",
    "    y_wh_ts.append(torch.from_numpy(np.array(y_wh_t[i])).to(device).to(torch.float32).view(-1,1))\n",
    "    y_sort_ts.append(torch.from_numpy(np.array(y_sort_t[i])).to(device).to(torch.float32).view(-1,1))\n",
    "    y_pack_ts.append(torch.from_numpy(np.array(y_pack_t[i])).to(device).to(torch.float32).view(-1,1))\n",
    "\n",
    "print('------------Load Data Success------------')\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "model.train()\n",
    "model.cuda()\n",
    "model.float()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00001)\n",
    "\n",
    "lossfunction = torch.nn.MSELoss()\n",
    "x_dict = graph.x_dict\n",
    "edge_index_dict = graph.edge_index_dict\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "if_first = True\n",
    "loss_whs = 0\n",
    "loss_packs =0\n",
    "loss_sorts = 0\n",
    "loss_alls = 0\n",
    "losss = 0\n",
    "sn = 0\n",
    "firstcat = True\n",
    "outall = None\n",
    "outwh = None\n",
    "outpack = None\n",
    "outsort = None\n",
    "cmask = cmask_ins\n",
    "dmask = downmask_ins\n",
    "\n",
    "for epoch in range(0,10000):\n",
    "    \n",
    "    model.train()\n",
    "    loss_whs = 0\n",
    "    loss_packs =0\n",
    "    loss_sorts = 0\n",
    "    loss_alls = 0\n",
    "    losss = 0\n",
    "    sn = 0\n",
    "    firstcat = True\n",
    "    outall = None\n",
    "    outwh = None\n",
    "    outpack = None\n",
    "    outsort = None\n",
    "\n",
    "    for t in train_range:\n",
    "        \n",
    "        \n",
    "        train_temporal_data = {\n",
    "            'Node1':train_data_wh[t].view(-1,4),\n",
    "            'Node2':train_data_sort[t].view(-1,4)\n",
    "        }\n",
    "        train_back_data = {\n",
    "            'Node1':train_data_background_wh[t].view(-1,3),\n",
    "            'Node2':train_data_background_sort[t].view(-1,3)\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "        y_wh_t = y_wh_ts[t]\n",
    "        y_pack_t = y_pack_ts[t]\n",
    "        y_sort_t = y_sort_ts[t]\n",
    "        y_all_t = y_all_ts[t]\n",
    "\n",
    "    \n",
    "        out = model(x_dict, edge_index_dict,train_temporal_data,train_back_data,mask_in,mask_pack_in,if_first,cmask,dmask,t)\n",
    "\n",
    "\n",
    "        whout_norm = out['Node1']\n",
    "        \n",
    "\n",
    "        packout_norm = out['pack']\n",
    "        \n",
    "\n",
    "        sortout_norm = out['Node2']\n",
    "        \n",
    "\n",
    "        allout_norm = out['Node1'] + out['pack'] + out['Node2']\n",
    "        \n",
    "\n",
    "        if firstcat:\n",
    "            firstcat = False\n",
    "            outall = allout_norm.cpu().detach()\n",
    "            outwh = whout_norm.cpu().detach()\n",
    "            outpack = packout_norm.cpu().detach()\n",
    "            outsort = sortout_norm.cpu().detach()\n",
    "        else:\n",
    "            outall = torch.cat((outall,allout_norm.cpu().detach()),dim=0)\n",
    "            outwh = torch.cat((outwh,whout_norm.cpu().detach()),dim=0)\n",
    "            outpack = torch.cat((outpack,packout_norm.cpu().detach()),dim=0)\n",
    "            outsort = torch.cat((outsort,sortout_norm.cpu().detach()),dim=0)\n",
    "        loss_wh = lossfunction(out['Node1'],y_wh_t)\n",
    "        loss_sort = lossfunction(out['Node2'],y_sort_t)\n",
    "        loss_pack = lossfunction(out['pack'],y_pack_t)\n",
    "        loss_all = lossfunction(out['Node1']+out['Node2']+out['pack'],y_all_t)\n",
    "        loss = loss_wh + loss_sort + loss_all + loss_pack\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        sn += len(y_all_t)\n",
    "        tn = len(y_all_t)\n",
    "\n",
    "        loss_whs += float(loss_wh) * tn\n",
    "        loss_packs += float(loss_pack) * tn\n",
    "        loss_sorts += float(loss_sort) * tn\n",
    "        loss_alls += float(loss_all) * tn\n",
    "        losss += float(loss) * tn\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if_first = False\n",
    "\n",
    "    pres = {\n",
    "        \"all\":outall,\n",
    "        \"store\":outwh,\n",
    "        \"pack\":outpack,\n",
    "        \"sort\":outsort\n",
    "    }\n",
    "    yts =  {\n",
    "        \"all\":y_all_t_all[0:312*N_train],\n",
    "        \"store\":y_wh_t_all[0:312*N_train],\n",
    "        \"pack\":y_pack_t_all[0:312*N_train],\n",
    "        \"sort\":y_sort_t_all[0:312*N_train]\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        with open(Logdir + \"train_record.txt\",'a+') as f:\n",
    "            print(\"epoch: {}, loss_wh: {}, loss_pack: {}, loss_sort: {}, loss_all: {}, loss: {}\".format(epoch,loss_whs/sn,loss_packs/sn,loss_sorts/sn,loss_alls/sn,losss/sn),file=f)\n",
    "        with open(Logdir + \"train_metric.txt\",\"a+\") as f:\n",
    "            print(metric_all(pres,yts),file=f)\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        print(\"-------train loss--------\")\n",
    "        endtime = datetime.datetime.now()\n",
    "        print(\"epoch: {}, loss_wh: {}, loss_pack: {}, loss_sort: {}, loss_all: {}, loss: {}, time: {}s\".format(epoch,loss_whs/sn,loss_packs/sn,loss_sorts/sn,loss_alls/sn,losss/sn,(endtime-starttime).seconds))\n",
    "        starttime = datetime.datetime.now()\n",
    "        r = metric_all(pres,yts)\n",
    "        print(\"-------train metric--------\")\n",
    "        for i in r:\n",
    "            print(i,r[i],end=' ')\n",
    "        print()\n",
    "            \n",
    "                \n",
    "    if epoch % 25 == 0:\n",
    "        torch.save(model,Logdir+\"Model_Save/{}_{}.pkl\".format(epoch,losss/sn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedhgt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
